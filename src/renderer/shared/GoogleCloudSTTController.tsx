import React, { useState, useRef, useCallback, useEffect } from 'react'
import { Play, Square, Mic, MicOff, Cloud } from 'lucide-react'
import { TranscriptSegment, RecordingState } from './audio/types'

interface GoogleCloudSTTControllerProps {
  onTranscriptUpdate: (segments: TranscriptSegment[]) => void
  onRecordingStateChange?: (state: RecordingState) => void
}

// Configura√ß√£o da API do Google Cloud
const GOOGLE_API_KEY = 'AIzaSyBfeqhkjNyXjmqI5OPoYb3CosyxwfyA8zY' // Sua chave de API
const GOOGLE_STT_ENDPOINT = 'https://speech.googleapis.com/v1/speech:recognize'

export function GoogleCloudSTTController({ onTranscriptUpdate, onRecordingStateChange }: GoogleCloudSTTControllerProps) {
  const [isRecording, setIsRecording] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [isTranscribing, setIsTranscribing] = useState(false)
  const [hasPermission, setHasPermission] = useState<boolean | null>(null)
  
  const segmentsRef = useRef<TranscriptSegment[]>([])
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const startTimeRef = useRef<number>(0)
  const streamRef = useRef<MediaStream | null>(null)
  const segmentStartTimeRef = useRef<number>(0)
  const transcriptionQueueRef = useRef<number>(0)

  const addSegment = useCallback((text: string, speaker: 'TERAPEUTA' | 'PACIENTE' | 'DESCONHECIDO' = 'TERAPEUTA', status: 'partial' | 'final' = 'final') => {
    const now = Date.now()
    const newSegment: TranscriptSegment = {
      start: now,
      end: now + (text.length * 50),
      speaker,
      text,
      status
    }
    
    segmentsRef.current.push(newSegment)
    onTranscriptUpdate([...segmentsRef.current])
    console.log('‚òÅÔ∏è Google Cloud STT:', text, '- Status:', status)
  }, [onTranscriptUpdate])

  const convertBlobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader()
      reader.onloadend = () => {
        if (reader.result) {
          const base64 = (reader.result as string).split(',')[1]
          resolve(base64)
        } else {
          reject(new Error('Falha ao converter √°udio para base64'))
        }
      }
      reader.onerror = reject
      reader.readAsDataURL(blob)
    })
  }

  const transcribeSegment = useCallback(async (audioBlob: Blob, segmentNumber: number) => {
    try {
      const queueNumber = ++transcriptionQueueRef.current
      console.log(`‚òÅÔ∏è Iniciando transcri√ß√£o do segmento ${segmentNumber} (fila: ${queueNumber})`)
      
      // Adicionar segmento tempor√°rio
      const tempSegment: TranscriptSegment = {
        start: segmentStartTimeRef.current,
        end: Date.now(),
        speaker: 'TERAPEUTA',
        text: `[Transcrevendo segmento ${segmentNumber}...]`,
        status: 'partial'
      }
      
      segmentsRef.current.push(tempSegment)
      onTranscriptUpdate([...segmentsRef.current])
      
      console.log('‚òÅÔ∏è Convertendo √°udio para base64...')
      const audioBase64 = await convertBlobToBase64(audioBlob)
      
      const requestBody = {
        config: {
          encoding: 'WEBM_OPUS',
          sampleRateHertz: 48000,
          languageCode: 'pt-BR',
          enableAutomaticPunctuation: true,
          enableWordTimeOffsets: false,
          model: 'latest_short', // Usar modelo curto para segmentos pequenos
          useEnhanced: true,
          maxAlternatives: 1,
          profanityFilter: false
        },
        audio: {
          content: audioBase64
        }
      }
      
      console.log(`‚òÅÔ∏è Enviando segmento ${segmentNumber} para Google Cloud STT...`)
      
      const response = await fetch(`${GOOGLE_STT_ENDPOINT}?key=${GOOGLE_API_KEY}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody)
      })
      
      if (!response.ok) {
        const errorData = await response.json()
        throw new Error(`Google STT API Error: ${response.status} - ${errorData.error?.message || 'Erro desconhecido'}`)
      }
      
      const result = await response.json()
      console.log(`‚òÅÔ∏è Resposta do segmento ${segmentNumber}:`, result)
      
      // Remover segmento tempor√°rio
      segmentsRef.current = segmentsRef.current.filter(seg => !seg.text.includes(`[Transcrevendo segmento ${segmentNumber}`))
      
      if (result.results && result.results.length > 0) {
        // Processar todos os resultados do segmento
        result.results.forEach((resultItem: any, index: number) => {
          if (resultItem.alternatives && resultItem.alternatives.length > 0) {
            const transcript = resultItem.alternatives[0].transcript
            const confidence = resultItem.alternatives[0].confidence || 0
            
            if (transcript && transcript.trim()) {
              const confidencePercent = Math.round(confidence * 100)
              const segmentText = `${transcript.trim()} (${confidencePercent}%)`
              
              console.log(`üìù Segmento ${segmentNumber}.${index + 1}:`, segmentText)
              
              const finalSegment: TranscriptSegment = {
                start: segmentStartTimeRef.current,
                end: Date.now(),
                speaker: 'TERAPEUTA',
                text: segmentText,
                status: 'final'
              }
              
              segmentsRef.current.push(finalSegment)
            }
          }
        })
      } else {
        console.log(`‚ö†Ô∏è Segmento ${segmentNumber} sem resultados`)
      }
      
      onTranscriptUpdate([...segmentsRef.current])
      
    } catch (error) {
      console.error(`‚ùå Erro na transcri√ß√£o do segmento ${segmentNumber}:`, error)
      
      // Remover segmento tempor√°rio
      segmentsRef.current = segmentsRef.current.filter(seg => !seg.text.includes(`[Transcrevendo segmento ${segmentNumber}`))
      
      const errorSegment: TranscriptSegment = {
        start: segmentStartTimeRef.current,
        end: Date.now(),
        speaker: 'TERAPEUTA',
        text: `[Erro no segmento ${segmentNumber}: ${error instanceof Error ? error.message : 'Erro desconhecido'}]`,
        status: 'final'
      }
      
      segmentsRef.current.push(errorSegment)
      onTranscriptUpdate([...segmentsRef.current])
    }
  }, [addSegment, onTranscriptUpdate])

  const startRecording = useCallback(async () => {
    try {
      console.log('‚òÅÔ∏è Iniciando Google Cloud STT...')
      setIsProcessing(true)
      
      if (!GOOGLE_API_KEY) {
        throw new Error('Chave de API do Google Cloud n√£o configurada')
      }
      
      // Reutilizar stream existente ou criar novo
      let stream = streamRef.current
      
      if (!stream || stream.getTracks().some(track => track.readyState === 'ended')) {
        console.log('üé§ Solicitando novo acesso ao microfone...')
        stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 48000
          }
        })
        streamRef.current = stream
        console.log('‚úÖ Nova permiss√£o de microfone concedida')
      } else {
        console.log('‚úÖ Reutilizando stream de microfone existente')
      }
      
      setHasPermission(true)
      
      // Configurar MediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      })
      
      mediaRecorderRef.current = mediaRecorder
      audioChunksRef.current = []
      let segmentNumber = 0
      
      mediaRecorder.ondataavailable = async (event) => {
        if (event.data.size > 0) {
          console.log('üìº Chunk de √°udio capturado:', event.data.size, 'bytes')
          
          // Processar este chunk automaticamente
          if (event.data.size > 1000) { // S√≥ processar se tiver conte√∫do significativo
            segmentNumber++
            segmentStartTimeRef.current = Date.now() - 3000 // Estimar in√≠cio do segmento
            
            console.log(`üöÄ Processando segmento ${segmentNumber} automaticamente...`)
            
            // Transcrever este segmento em paralelo
            transcribeSegment(event.data, segmentNumber).catch(error => {
              console.error(`‚ùå Erro ao processar segmento ${segmentNumber}:`, error)
            })
          }
          
          // Manter chunks para grava√ß√£o final (se necess√°rio no futuro)
          audioChunksRef.current.push(event.data)
        }
      }
      
      mediaRecorder.onstop = async () => {
        console.log('üìº Grava√ß√£o finalizada')
        console.log('üìº Total de chunks processados:', audioChunksRef.current.length)
        
        // N√£o fazer transcri√ß√£o aqui - j√° foi feita em tempo real
        addSegment(`[Grava√ß√£o finalizada - ${segmentNumber} segmentos processados]`, 'TERAPEUTA')
      }
      
      mediaRecorder.onerror = (event) => {
        console.error('‚ùå Erro no MediaRecorder:', event)
        addSegment('[Erro na grava√ß√£o de √°udio]', 'TERAPEUTA')
      }
      
      // N√£o limpar segmentos anteriores - manter hist√≥rico
      // segmentsRef.current = []
      // onTranscriptUpdate([])
      
      startTimeRef.current = Date.now()
      setIsRecording(true)
      setIsProcessing(false)
      
      // Notificar mudan√ßa de estado
      onRecordingStateChange?.({
        isRecording: true,
        isProcessing: false,
        systemAudioAvailable: false
      })
      
      // Iniciar grava√ß√£o com timeslice para transcri√ß√£o em tempo real
      mediaRecorder.start(3000) // Captura dados a cada 3 segundos para transcri√ß√£o
      
      console.log('üé§ Google Cloud STT iniciado - fale no microfone!')
      
      // Adicionar separador se j√° houver segmentos
      if (segmentsRef.current.length > 0) {
        addSegment('--- Nova Grava√ß√£o ---', 'TERAPEUTA')
      } else {
        addSegment('[Primeira grava√ß√£o iniciada]', 'TERAPEUTA')
      }
      
    } catch (error) {
      console.error('‚ùå Erro ao iniciar Google Cloud STT:', error)
      setIsProcessing(false)
      setHasPermission(false)
      
      addSegment(`[Erro: ${error instanceof Error ? error.message : 'Erro desconhecido'}]`, 'TERAPEUTA')
    }
  }, [transcribeSegment, onRecordingStateChange, addSegment])

  const stopRecording = useCallback(async () => {
    try {
      console.log('‚èπÔ∏è Parando Google Cloud STT...')
      setIsProcessing(true)
      
      // Parar grava√ß√£o
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop()
      }
      
      setIsRecording(false)
      
      // Notificar mudan√ßa de estado
      onRecordingStateChange?.({
        isRecording: false,
        isProcessing: true, // Manter como processando at√© finalizar
        systemAudioAvailable: false
      })
      
      const duration = Date.now() - startTimeRef.current
      const durationSeconds = Math.round(duration / 1000)
      
      console.log('‚úÖ Google Cloud STT finalizado. Dura√ß√£o:', durationSeconds, 'segundos')
      
      // Finalizar imediatamente - transcri√ß√£o j√° foi feita em tempo real
      setIsProcessing(false)
      
      // N√£o parar o stream aqui - mant√™-lo para pr√≥ximas grava√ß√µes
      // if (streamRef.current) {
      //   streamRef.current.getTracks().forEach(track => track.stop())
      //   streamRef.current = null
      // }
      
      const transcriptSegments = segmentsRef.current.filter(s => !s.text.includes('[') && s.status === 'final')
      addSegment(`[Sess√£o finalizada - ${transcriptSegments.length} segmentos transcritos em ${durationSeconds}s]`, 'TERAPEUTA')
      
      console.log(`‚úÖ Sess√£o finalizada com ${transcriptSegments.length} segmentos transcritos`)
      
      // Preparar para funcionalidade futura (salvar, processar, etc.)
      console.log('üîÆ Bot√£o parar pronto para funcionalidade futura...')
      
    } catch (error) {
      console.error('‚ùå Erro ao parar Google Cloud STT:', error)
      setIsProcessing(false)
    }
  }, [addSegment, onRecordingStateChange])

  // Limpeza ao desmontar
  useEffect(() => {
    return () => {
      console.log('üßπ Limpando GoogleCloudSTTController...')
      if (streamRef.current) {
        console.log('üßπ Parando stream de microfone...')
        streamRef.current.getTracks().forEach(track => track.stop())
        streamRef.current = null
      }
      if (mediaRecorderRef.current) {
        console.log('üßπ Parando MediaRecorder...')
        if (mediaRecorderRef.current.state === 'recording') {
          mediaRecorderRef.current.stop()
        }
        mediaRecorderRef.current = null
      }
    }
  }, [])

  // Verificar permiss√£o inicial
  useEffect(() => {
    navigator.mediaDevices.getUserMedia({ audio: true })
      .then((stream) => {
        stream.getTracks().forEach(track => track.stop())
        setHasPermission(true)
      })
      .catch(() => {
        setHasPermission(false)
      })
  }, [])

  if (!GOOGLE_API_KEY) {
    return (
      <button
        disabled
        className="event-layer w-[32px] h-[32px] rounded-full bg-yellow-500/20 border border-yellow-500/30 text-yellow-300 flex items-center justify-center cursor-not-allowed"
        title="Chave de API do Google Cloud n√£o configurada"
      >
        <Cloud size={16} />
      </button>
    )
  }

  if (hasPermission === false) {
    return (
      <button
        onClick={() => window.location.reload()}
        className="event-layer w-[32px] h-[32px] rounded-full bg-red-500/20 border border-red-500/30 text-red-300 flex items-center justify-center hover:scale-105"
        title="Permiss√£o de microfone negada - clique para recarregar"
      >
        <MicOff size={16} />
      </button>
    )
  }

  return (
    <button
      onClick={isRecording ? stopRecording : startRecording}
      disabled={isProcessing}
      className={`event-layer w-[32px] h-[32px] rounded-full border text-white/90 flex items-center justify-center hover:scale-105 active:scale-95 focus:outline-none focus:ring-2 focus:ring-white/30 transition-all duration-200 ${
        isRecording 
          ? isTranscribing 
            ? 'bg-blue-500/90 border-blue-400 animate-pulse shadow-lg shadow-blue-500/50 scale-110' 
            : 'bg-red-500/90 border-red-400 animate-pulse shadow-lg shadow-red-500/50'
          : 'bg-white/10 border-white/20 hover:bg-white/15 hover:border-white/30'
      } ${isProcessing ? 'opacity-50 cursor-not-allowed animate-spin' : ''}`}
      aria-label={isRecording ? 'Parar grava√ß√£o' : 'Iniciar grava√ß√£o'}
      title={
        isRecording 
          ? isTranscribing 
            ? 'Google Cloud STT - transcrevendo...' 
            : 'Google Cloud STT - gravando'
          : 'Iniciar Google Cloud Speech-to-Text'
      }
    >
      {isRecording ? <Square size={16} /> : <Cloud size={16} />}
    </button>
  )
}
